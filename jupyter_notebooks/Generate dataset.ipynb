{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pprint\n",
    "import os\n",
    "import random\n",
    "\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from esc_identifier.cluster import distance_matrix, dbscan, get_clusters\n",
    "from esc_identifier.distance import token_set_distance, levenshtein\n",
    "from esc_identifier.utils.string import (\n",
    "    normalize_human_name, normalize_affiliation)\n",
    "from jupyter_utils import log_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MONGO_URI = 'mongodb://localhost:27017/'\n",
    "\n",
    "mongo_client = MongoClient(MONGO_URI)\n",
    "kdd_db = mongo_client.kdd2013\n",
    "author_raw_collection = kdd_db.author_raw\n",
    "author_collection = kdd_db.author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning raw metadata\n",
    "Clean authors metadata from `author_raw` collection and save to `author` collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_list(lst, distance_function, dbscan_eps):\n",
    "    if not lst:\n",
    "        return []\n",
    "\n",
    "    indices_clusters = (\n",
    "        get_clusters(\n",
    "            lst,\n",
    "            distance_function=distance_function,\n",
    "            eps=dbscan_eps\n",
    "        )\n",
    "    )\n",
    "    clusters = [\n",
    "        [lst[i] for i in cluster]\n",
    "        for cluster\n",
    "        in indices_clusters\n",
    "    ]\n",
    "\n",
    "    biggest_cluster = max(indices_clusters, key=len)\n",
    "    \n",
    "    true_cluster = [lst[idx] for idx in biggest_cluster]\n",
    "    \n",
    "    return true_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_eps = 0.3\n",
    "affiliation_eps = 0.1\n",
    "\n",
    "def process_author(author_raw, distance_function):\n",
    "    author_processed = author_raw.copy()\n",
    "\n",
    "    affiliations_raw = author_raw['affiliations']\n",
    "    normalized_affiliations = [\n",
    "        normalize_affiliation(affiliation)\n",
    "        for affiliation\n",
    "        in affiliations_raw\n",
    "    ]\n",
    "    affiliations_not_empty = list(filter(len, normalized_affiliations))\n",
    "    affiliations_processed = clean_list(\n",
    "            lst=affiliations_not_empty,\n",
    "            distance_function=distance_function,\n",
    "            dbscan_eps=affiliation_eps\n",
    "    )\n",
    "    author_processed['affiliations'] = list(set(affiliations_processed))\n",
    "    assert all(author_processed['affiliations'])\n",
    "    \n",
    "    names_raw = author_raw['names']\n",
    "    normalized_names = [\n",
    "        normalize_human_name(name)\n",
    "        for name\n",
    "        in names_raw\n",
    "    ]\n",
    "    names_processed = clean_list(\n",
    "        lst=normalized_names,\n",
    "        distance_function=distance_function,\n",
    "        dbscan_eps=name_eps\n",
    "    )\n",
    "    author_processed['names'] = list(set(names_processed))\n",
    "    assert all(author_processed['names'])\n",
    "    \n",
    "    return author_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_function = token_set_distance\n",
    "authors_raw = author_raw_collection.find()\n",
    "authors_raw_count = authors_raw.count()\n",
    "\n",
    "processed_authors = []\n",
    "for index, author in log_progress(authors_raw, every=1, size=authors_raw_count):\n",
    "    if not author['affiliations']:\n",
    "        continue\n",
    "    \n",
    "    processed_authors.append(\n",
    "        process_author(author, distance_function)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_collection.delete_many({})\n",
    "result = author_collection.insert_many(processed_authors)\n",
    "n_inserted_doc = len(result.inserted_ids)\n",
    "print(f'Inserted {n_inserted_doc} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uniform_select(iterable, k):\n",
    "    iterable = list(iterable)\n",
    "    selection_indices = np.linspace(0, len(iterable) - 1, k, dtype=np.int8)\n",
    "    selection = [iterable[idx] for idx in selection_indices]\n",
    "    \n",
    "    return selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_dataset(metadata):\n",
    "    X_positive = []\n",
    "    X_negative = []\n",
    "\n",
    "    for author_idx, author_metadata in enumerate(metadata):\n",
    "        kdd_id = author_metadata['kdd_id']\n",
    "        names = author_metadata['names']\n",
    "        affiliations = author_metadata['affiliations']\n",
    "\n",
    "        selection_size = min(5, max(len(names), len(affiliations)))\n",
    "        if selection_size == 1:\n",
    "            continue\n",
    "\n",
    "        sorted_names = sorted(names, key=len, reverse=True)\n",
    "        selected_names = uniform_select(sorted_names, selection_size)\n",
    "\n",
    "        sorted_affiliations = sorted(affiliations, key=len, reverse=True)\n",
    "        selected_affiliations = uniform_select(sorted_affiliations, selection_size)\n",
    "\n",
    "        # positive samples\n",
    "        metadata_vectors = list(zip(selected_names, selected_affiliations))\n",
    "        for (a, b) in itertools.combinations(metadata_vectors, 2):\n",
    "            distance = metadata_vector_distance(a, b)\n",
    "            X_positive.append(distance)\n",
    "\n",
    "        # negative samples\n",
    "        other_authors = random.sample(metadata[:author_idx] + metadata[author_idx + 1:],\n",
    "                                      k=selection_size)\n",
    "        other_authors_metadata_vectors = [\n",
    "            [random.choice(author['names']), random.choice(author['affiliations'])]\n",
    "            for author\n",
    "            in other_authors \n",
    "        ]\n",
    "        for (a, b) in itertools.product(metadata_vectors, other_authors_metadata_vectors):\n",
    "            distance = metadata_vector_distance(a, b)\n",
    "            if all(d < 0.3 for d in distance):\n",
    "                pprint.pprint(['False-negative sample', a, b, distance])\n",
    "                continue\n",
    "            X_negative.append(distance)\n",
    "            \n",
    "        for (name_1, name_2, other_author) in zip(selected_names,\n",
    "                                                  selected_names[1:] + [selected_names[0]],\n",
    "                                                  other_authors):\n",
    "            a = (name_1, random.choice(selected_affiliations))\n",
    "            b = (name_2, random.choice(other_author['affiliations']))\n",
    "            distance = metadata_vector_distance(a, b)\n",
    "            if all(d < 0.3 for d in distance):\n",
    "                pprint.pprint(['False-negative sample', a, b, distance])\n",
    "                continue\n",
    "            X_negative.append(distance)\n",
    "#             print(a)\n",
    "#             print(b)\n",
    "#             print(distance)\n",
    "#             print()\n",
    "        \n",
    "    print(f'positive samples: {len(X_positive)}')\n",
    "    print(f'negative samples: {len(X_negative)}')\n",
    "    X = X_positive + X_negative\n",
    "    y = [1] * len(X_positive) + [0] * len(X_negative)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_cached = list(author_collection.find())\n",
    "print(f'{len(authors_cached)} authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 3000\n",
    "train_metadata = authors_cached[:train_size]\n",
    "test_metadata = authors_cached[train_size:]\n",
    "\n",
    "X_train, y_train = generate_dataset(train_metadata)\n",
    "X_test, y_test = generate_dataset(test_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets_dir = 'datasets'\n",
    "np.save(os.path.join(datasets_dir, 'train-authors'), X_train)\n",
    "np.save(os.path.join(datasets_dir, 'train-authors-labels'), y_train)\n",
    "np.save(os.path.join(datasets_dir, 'test-authors'), X_test)\n",
    "np.save(os.path.join(datasets_dir, 'test-authors-labels'), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "pd.DataFrame({\n",
    "    'distance': pd.Series(random.sample(X_train, 100)),\n",
    "    'label': pd.Series(random.sample(y_train, 100))\n",
    "}).sort_values('distance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = ['Olga Demurin', 'Novosibirsk']\n",
    "b = ['Oleg Demurin', 'Novosibirsk']\n",
    "metadata_vector_distance(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
