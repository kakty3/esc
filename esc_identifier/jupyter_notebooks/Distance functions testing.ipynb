{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from itertools import chain\n",
    "import functools\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from esc_identifier.distance import (\n",
    "    # Frequence based distances\n",
    "    ratio_distance,\n",
    "    partial_ratio_distance,\n",
    "    token_sort_distance,\n",
    "    partial_token_sort_distance,\n",
    "    token_set_distance,\n",
    "    partial_token_set_distance,\n",
    "    # Edit distances\n",
    "    jaro_distance,\n",
    "    jaro_winkler_distance,\n",
    "    levenshtein,\n",
    "    levenshtein_sort,\n",
    "    damerau_levenshtein,\n",
    ")\n",
    "from esc_identifier.cluster import dbscan, get_clusters\n",
    "# from esc_identifier.utils import prepare_string\n",
    "from esc_identifier.string_process.affiliation import prepare_affiliation\n",
    "from esc_identifier.string_process.human_name import prepare_human_name\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MONGO_URI = 'mongodb://localhost:27017/'\n",
    "\n",
    "mongo_client = MongoClient(MONGO_URI)\n",
    "kdd_db = mongo_client.kdd2013\n",
    "author_collection = kdd_db.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "author_cache = list(author_collection.find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['computer science katholieke', 'katholieke leuven computer science celestijnenlaan 200a 3001 belgium']]\n"
     ]
    }
   ],
   "source": [
    "affiliations_data = [\n",
    "    list(map(prepare_affiliation, author['affiliations']))\n",
    "    for author\n",
    "    in author_cache\n",
    "]\n",
    "print(affiliations_data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bart vandereycken']]\n"
     ]
    }
   ],
   "source": [
    "names_data = [\n",
    "    list(map(prepare_human_name, author['names']))\n",
    "    for author\n",
    "    in author_cache\n",
    "]\n",
    "print(names_data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_test_data(dataset, size, sample_length, max_variations):\n",
    "    X_test, y_test = [], []\n",
    "\n",
    "    for _ in range(size):\n",
    "        data_sample = random.sample(dataset, sample_length)\n",
    "        clusters = [random.sample(item,\n",
    "                                  random.randint(1,\n",
    "                                                 min(len(item),\n",
    "                                                     max_variations)\n",
    "                                                )\n",
    "                                 )\n",
    "                    for item\n",
    "                    in data_sample]\n",
    "        y_true = list(itertools.chain.from_iterable([i] * len(cluster) for i, cluster in enumerate(clusters)))\n",
    "        X_test.append(list(itertools.chain.from_iterable(clusters)))\n",
    "        y_test.append(y_true)\n",
    "    \n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = affiliations_data\n",
    "test_data_size = 100\n",
    "sample_size = 5\n",
    "max_variations = 5\n",
    "random_seed = 42\n",
    "\n",
    "random.seed(random_seed)\n",
    "\n",
    "X_test, y_test = generate_test_data(dataset=dataset,\n",
    "                                    size=test_data_size,\n",
    "                                    sample_length=sample_size,\n",
    "                                    max_variations=max_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token sort ratio ... Done\n",
      "Token set ratio ... Done\n",
      "Levenshtein ... Done\n",
      "Levenshtein sort ... Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eps</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f-beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Token set ratio</th>\n",
       "      <td>0.282449</td>\n",
       "      <td>0.852074</td>\n",
       "      <td>0.842098</td>\n",
       "      <td>0.839973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token sort ratio</th>\n",
       "      <td>0.518571</td>\n",
       "      <td>0.563860</td>\n",
       "      <td>0.551246</td>\n",
       "      <td>0.539323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein</th>\n",
       "      <td>0.663878</td>\n",
       "      <td>0.518938</td>\n",
       "      <td>0.501813</td>\n",
       "      <td>0.491283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein sort</th>\n",
       "      <td>0.645714</td>\n",
       "      <td>0.519847</td>\n",
       "      <td>0.501792</td>\n",
       "      <td>0.490739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eps  precision    recall    f-beta\n",
       "Token set ratio   0.282449   0.852074  0.842098  0.839973\n",
       "Token sort ratio  0.518571   0.563860  0.551246  0.539323\n",
       "Levenshtein       0.663878   0.518938  0.501813  0.491283\n",
       "Levenshtein sort  0.645714   0.519847  0.501792  0.490739"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "distance_functions = [\n",
    "#     (ratio_distance, 'Ratio'),\n",
    "#     (partial_ratio_distance, 'Partial ratio'),\n",
    "    (token_sort_distance, 'Token sort ratio'),\n",
    "#     (partial_token_sort_distance, 'Partial token sort ratio'),\n",
    "    (token_set_distance, 'Token set ratio'),\n",
    "#     (partial_token_set_distance, 'Partial token set ratio'),\n",
    "#     (jaro_distance, 'Jaro'),\n",
    "#     (jaro_winkler_distance, 'Jaro-Winkler'),\n",
    "    (levenshtein, 'Levenshtein'),\n",
    "    (levenshtein_sort, 'Levenshtein sort'),\n",
    "#     (damerau_levenshtein, 'Damerau-Levenshtein'),\n",
    "#     (most_freq_k_sdf_normalized, 'MostFreqKSDF')\n",
    "]\n",
    "\n",
    "# avg_f = min\n",
    "# avg_f = np.median\n",
    "avg_f = np.mean\n",
    "# avg_f = scipy.stats.hmean\n",
    "\n",
    "eps_range = np.linspace(0.01, 0.9, 50)\n",
    "df = pd.DataFrame()\n",
    "\n",
    "precision_recall_fbeta = {}\n",
    "\n",
    "for (distance_function, distance_function_name) in distance_functions:\n",
    "    print(f'{distance_function_name} ... ', end='')\n",
    "    global_precision, global_recall, global_fbeta_score = [], [], []\n",
    "\n",
    "    for eps in eps_range:\n",
    "        measurements = []\n",
    "        for X, y_true in zip(X_test, y_test):\n",
    "            clusters_pred = get_clusters(X, distance_function=distance_function, eps=eps)\n",
    "            y_pred = []\n",
    "            for i in range(len(y_true)):\n",
    "                cluster_index = list(cluster_idx\n",
    "                                     for cluster_idx, cluster\n",
    "                                     in enumerate(clusters_pred)\n",
    "                                     if i in cluster\n",
    "                                    )[0]\n",
    "                y_pred.append(cluster_index)\n",
    "            precision, recall, fbeta_score, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "            measurements.append((precision, recall, fbeta_score))\n",
    "    #         print(eps, precision_recall_fscore_support(y_true, y_pred, average='micro'))\n",
    "    #         print(eps, precision_recall_fscore_support(y_true, y_pred, average='weighted'))\n",
    "        p, r, f1 = list(zip(*measurements))\n",
    "        global_precision.append(avg_f(p))\n",
    "        global_recall.append(avg_f(r))\n",
    "        global_fbeta_score.append(avg_f(f1))\n",
    "    \n",
    "#     print(global_fbeta_score)\n",
    "#     print(hmean(np.vstack((global_precision, global_recall))))\n",
    "    precision_recall_fbeta[distance_function_name] = (global_precision, global_recall, global_fbeta_score)\n",
    "\n",
    "    best_eps, best_fbeta, best_precision, best_recall = \\\n",
    "        max(zip(eps_range,\n",
    "                global_fbeta_score,\n",
    "                global_precision,\n",
    "                global_recall\n",
    "               ),\n",
    "            key=lambda x: x[1])\n",
    "\n",
    "    df = df.append(\n",
    "        pd.DataFrame({\n",
    "            'eps': [best_eps],\n",
    "            'precision': [best_precision],\n",
    "            'recall': [best_recall],\n",
    "            'f-beta': [best_fbeta],\n",
    "#             'f-beta': [hmean(np.vstack((precision, recall)))[0]],\n",
    "        },\n",
    "        columns=['eps', 'precision', 'recall', 'f-beta'],\n",
    "        index=[distance_function_name])\n",
    "    )\n",
    "    \n",
    "    print(f'Done')\n",
    "    \n",
    "df.sort_values('f-beta', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rc('font', size=16) \n",
    "plt.rc('lines', color='k')\n",
    "plt.rc('axes',\n",
    "       prop_cycle=cycler('linestyle', ['-.', '--', '-']))\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, sharex=True, sharey=True, figsize=(20, 10))\n",
    "\n",
    "for (distance_function_name, (precision, recall, fbeta)), axis in zip(precision_recall_fbeta.items(), axes.ravel()):\n",
    "    axis.set_title(distance_function_name)\n",
    "    axis.set_ylim([0, 1])   \n",
    "    axis.set_xlabel(r'$\\varepsilon$')\n",
    "    axis.set_ylabel('score')\n",
    "\n",
    "    l_precision, = axis.plot(eps_range, precision, markevery=10)\n",
    "    l_recall, = axis.plot(eps_range, recall, markevery=2)\n",
    "    l_fbeta, = axis.plot(eps_range, fbeta, markevery=2)\n",
    "#     axis.plot([0.853618, 0.853618], 'k--', linewidth=1.0)\n",
    "\n",
    "fig.legend((l_precision, l_recall, l_fbeta),\n",
    "           labels=('Precision', 'Recall', r'$F_1$'),\n",
    "           ncol=3,\n",
    "           loc='upper center');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rc('font', size=16) \n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for distance_function_name, (precision, recall, fbeta) in precision_recall_fbeta.items():\n",
    "    plt.plot(eps_range, fbeta, label=distance_function_name, linewidth=3.0)\n",
    "\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.xlabel(r'$\\varepsilon$')\n",
    "plt.ylabel('f-beta')\n",
    "\n",
    "plt.legend(loc='best', prop={'size': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "\n",
    "plt.rc('font', size=14) \n",
    "plt.rc('lines', color='k')\n",
    "plt.rc('axes',\n",
    "       prop_cycle=cycler('marker', ['', '>']))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# for distance_function_name, (precision, recall, fbeta) in precision_recall_fbeta.items():\n",
    "f = 'Token set ratio'\n",
    "plt.plot(eps_range,\n",
    "         precision_recall_fbeta[f][2],\n",
    "         label=f)\n",
    "\n",
    "f = 'Levenshtein'\n",
    "plt.plot(eps_range,\n",
    "         precision_recall_fbeta[f][2],\n",
    "         label=f)\n",
    "\n",
    "fbeta_optimal = df.sort_values('f-beta', ascending=False)[:1]['eps']\n",
    "plt.plot([fbeta_optimal, fbeta_optimal], [0, 1], 'k--', linewidth=1.0)\n",
    "\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.xlabel(r'$\\varepsilon$')\n",
    "plt.ylabel(r'$F_1$')\n",
    "\n",
    "plt.legend(loc='best', prop={'size': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d(s1, s2) = 0.38\n",
      "d(s2, s3) = 0.14\n",
      "d(s1, s3) = 0.38\n"
     ]
    }
   ],
   "source": [
    "s1 = 'kitten'\n",
    "s2 = 'sittinn'\n",
    "s3 = 'sitting'\n",
    "print(f'd(s1, s2) = {token_set_distance(s1, s2)}')\n",
    "print(f'd(s2, s3) = {token_set_distance(s2, s3)}')\n",
    "print(f'd(s1, s3) = {token_set_distance(s1, s3)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
