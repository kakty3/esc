{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import textwrap\n",
    "\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.schema import MetaData\n",
    "from python_utils.data_access import check_connection as pg_check_connection\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "from esc_identifier.author import Author, RealAuthor\n",
    "from esc_identifier.author.distance import author_distance\n",
    "from esc_identifier.author.utils import to_real_author\n",
    "from esc_identifier.utils.string import normalize_author\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield index, record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ESC_DB_URI = 'postgresql://root:secret@localhost:5432/esc'\n",
    "KDD_DB_URI = 'postgresql://root:secret@localhost:5432/Kdd2013AuthorPaperIdentification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pg_check_connection(ESC_DB_URI)\n",
    "pg_check_connection(KDD_DB_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MONGO_URI = 'mongodb://localhost:27017/'\n",
    "\n",
    "mongo_client = MongoClient(MONGO_URI)\n",
    "esc_db = mongo_client.esc\n",
    "real_author_collection = esc_db.real_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sa_url = sa.engine.url.make_url(KDD_DB_URI)\n",
    "\n",
    "engine = create_engine(sa_url)\n",
    "\n",
    "meta = MetaData()\n",
    "meta.reflect(bind=engine)\n",
    "\n",
    "author_table = meta.tables['author']\n",
    "\n",
    "DBSession = sessionmaker(bind=engine)\n",
    "session = DBSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model \"models/svm-poly.pickle\"\n"
     ]
    }
   ],
   "source": [
    "models_dir = 'models'\n",
    "model_path = os.path.join(models_dir, f'svm-poly.pickle')\n",
    "with open(model_path, 'rb') as model_file:\n",
    "    classifier = pickle.load(model_file)\n",
    "    print(f'Loaded model \"{model_path}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "author_dict = RealAuthor(\n",
    "    kdd_author_ids=[1,2],\n",
    "    name='pidr',\n",
    "    affiliation='gnidos'\n",
    ")._asdict()\n",
    "author_dict['_id'] = 1\n",
    "result = real_author_collection.insert_one(author_dict)\n",
    "# inserted_docs_count = len(result.inserted_ids)\n",
    "# print(f'Inserted {inserted_docs_count} documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4647b3981674beab148131d6287758c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 200/247121 authors\n",
      "Total time: 3.306046962738037 s    \n",
      "\n",
      "Progress: 300/247121 authors\n",
      "Total time: 3.2792670726776123 s    \n",
      "\n",
      "Progress: 400/247121 authors\n",
      "Total time: 5.034348726272583 s    \n",
      "\n",
      "Progress: 500/247121 authors\n",
      "Total time: 2.570261001586914 s    \n",
      "\n",
      "Progress: 600/247121 authors\n",
      "Total time: 3.6742000579833984 s    \n",
      "\n",
      "Progress: 800/247121 authors\n",
      "Total time: 9.93295407295227 s    \n",
      "\n",
      "Progress: 900/247121 authors\n",
      "Total time: 6.200567007064819 s    \n",
      "\n",
      "Progress: 1000/247121 authors\n",
      "Total time: 5.806123733520508 s    \n",
      "\n",
      "Total time: 39.82888078689575 s\n"
     ]
    }
   ],
   "source": [
    "same_authors_threshold = 0.98\n",
    "update_every = 100\n",
    "limit = 1000\n",
    "name_distance_threshold = 0.33\n",
    "\n",
    "authors_count = session.query(sa.func.count(author_table.c.id)).one()[0]\n",
    "\n",
    "query = (\n",
    "    session.query(author_table)\n",
    "    .order_by(author_table.c.name)\n",
    ")\n",
    "\n",
    "real_authors = []\n",
    "\n",
    "total_tic = time.time()\n",
    "tic = time.time()\n",
    "\n",
    "for index, author_row in log_progress(query[:limit], every=1):\n",
    "    author = Author(\n",
    "        kdd_id=author_row.id,\n",
    "        name=author_row.name,\n",
    "        affiliation=author_row.affiliation\n",
    "    )\n",
    "    normalized_author = normalize_author(author)\n",
    "\n",
    "    # find faster way: predict_proba for each author or for batch of them\n",
    "    distances_with_real_authors = np.empty(shape=(0,2))\n",
    "    real_authors_indices = []\n",
    "    for real_author_idx, real_author in enumerate(real_authors):\n",
    "        distance = author_distance(normalized_author, real_author)\n",
    "        if distance[0] > name_distance_threshold:\n",
    "            continue\n",
    "            \n",
    "        distances_with_real_authors = np.vstack((\n",
    "            distances_with_real_authors,\n",
    "            np.array(distance)\n",
    "        ))\n",
    "        real_authors_indices.append(\n",
    "            real_author_idx\n",
    "        )\n",
    "    try:\n",
    "        are_same_authors_probabilities = classifier.predict_proba(\n",
    "            distances_with_real_authors\n",
    "        )[:, 1]\n",
    "    except(ValueError):\n",
    "        real_authors.append(to_real_author(author))\n",
    "        continue\n",
    "\n",
    "    if max(are_same_authors_probabilities) < same_authors_threshold:\n",
    "        real_authors.append(to_real_author(author))\n",
    "    else: \n",
    "        real_author_idx = int(np.argmax(are_same_authors_probabilities))\n",
    "        real_authors[real_author_idx].kdd_author_ids.append(author.kdd_id)\n",
    "    \n",
    "    if index % update_every == 0:\n",
    "        print(textwrap.dedent(f'''\n",
    "            Progress: {index}/{authors_count} authors\n",
    "            Total time: {time.time() - tic} s    \n",
    "        ''').lstrip())\n",
    "        \n",
    "        with open('benchmark.tmp', 'wb+') as tmp_file:\n",
    "            pickle.dump({\n",
    "                'real_authors': real_authors,\n",
    "                'last_author_idx': index - 2,\n",
    "            }, tmp_file)        \n",
    "            \n",
    "        tic = time.time()\n",
    "\n",
    "print(f'Total time: {time.time() - total_tic} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.53,  1.  ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(\n",
    "    [[ 0.6,   1.  ],\n",
    "     [ 0.61,  1.  ],\n",
    "     [ 0.67,  1.  ],\n",
    "     [ 0.53,  1.  ],\n",
    "     [ 0.63,  1.  ]]\n",
    ")\n",
    "a[a[:,0] < 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([])\n",
    "np.concatenate((b, np.array([1,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
