{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import textwrap\n",
    "\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.schema import MetaData\n",
    "from python_utils.data_access import check_connection as pg_check_connection\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "from esc_identifier.author import Author, RealAuthor\n",
    "from esc_identifier.author.distance import author_distance\n",
    "from esc_identifier.author.utils import to_real_author\n",
    "from esc_identifier.utils.string import normalize_author\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield index, record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ESC_DB_URI = 'postgresql://root:secret@localhost:5432/esc'\n",
    "KDD_DB_URI = 'postgresql://root:secret@localhost:5432/Kdd2013AuthorPaperIdentification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pg_check_connection(ESC_DB_URI)\n",
    "pg_check_connection(KDD_DB_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MONGO_URI = 'mongodb://localhost:27017/'\n",
    "\n",
    "mongo_client = MongoClient(MONGO_URI)\n",
    "esc_db = mongo_client.esc\n",
    "real_author_collection = esc_db.real_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sa_url = sa.engine.url.make_url(KDD_DB_URI)\n",
    "\n",
    "engine = create_engine(sa_url)\n",
    "\n",
    "meta = MetaData()\n",
    "meta.reflect(bind=engine)\n",
    "\n",
    "author_table = meta.tables['author']\n",
    "\n",
    "DBSession = sessionmaker(bind=engine)\n",
    "session = DBSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model \"models/svm-poly.pickle\"\n"
     ]
    }
   ],
   "source": [
    "models_dir = 'models'\n",
    "model_path = os.path.join(models_dir, f'svm-poly.pickle')\n",
    "with open(model_path, 'rb') as model_file:\n",
    "    classifier = pickle.load(model_file)\n",
    "    print(f'Loaded model \"{model_path}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# author_dict = RealAuthor(\n",
    "#     kdd_author_ids=[1,2],\n",
    "#     name='pidr',\n",
    "#     affiliation='gnidos'\n",
    "# )._asdict()\n",
    "# author_dict['_id'] = 1\n",
    "# result = real_author_collection.insert_one(author_dict)\n",
    "# inserted_docs_count = len(result.inserted_ids)\n",
    "# print(f'Inserted {inserted_docs_count} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify bunch: 39.82888078689575 s for 1000 authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794eab3b098544d1ba1a32c95706d1a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 63.48866605758667 s\n",
      " "
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "\n",
    "same_authors_threshold = 0.98\n",
    "# update_every = 100\n",
    "limit = 1500\n",
    "name_distance_threshold = 0.33\n",
    "\n",
    "# authors_count = session.query(sa.func.count(author_table.c.id)).one()[0]\n",
    "\n",
    "query = (\n",
    "    session.query(author_table)\n",
    "    .order_by(author_table.c.name)\n",
    ")\n",
    "real_authors = []\n",
    "total_tic = time.time()\n",
    "tic = time.time()\n",
    "\n",
    "for index, author_row in log_progress(query[:limit], every=10):\n",
    "    author = Author(\n",
    "        kdd_id=author_row.id,\n",
    "        name=author_row.name,\n",
    "        affiliation=author_row.affiliation\n",
    "    )\n",
    "    normalized_author = normalize_author(author)\n",
    "    \n",
    "    distances_with_real_authors = np.array([\n",
    "        author_distance(normalized_author, real_author)\n",
    "        for real_author\n",
    "        in filter(lambda a: a.name.startswith(author.name[0]), real_authors)\n",
    "    ])\n",
    "    \n",
    "    if not len(distances_with_real_authors):\n",
    "        real_authors.append(to_real_author(author))\n",
    "        continue\n",
    "    \n",
    "    real_author_indices = np.arange(len(real_authors))[\n",
    "        np.where(distances_with_real_authors[:, 0] < name_distance_threshold)\n",
    "    ]\n",
    "\n",
    "    if not len(real_author_indices):\n",
    "        real_authors.append(to_real_author(author))\n",
    "        continue\n",
    "\n",
    "    are_same_authors_probabilities = classifier.predict_proba(\n",
    "        distances_with_real_authors[real_author_indices]\n",
    "    )[:, 1]\n",
    "\n",
    "    if max(are_same_authors_probabilities) < same_authors_threshold:\n",
    "        real_authors.append(to_real_author(author))\n",
    "    else: \n",
    "        real_author_idx = int(np.argmax(are_same_authors_probabilities))\n",
    "        real_authors[real_author_idx].kdd_author_ids.append(author.kdd_id)\n",
    "    \n",
    "#     if update_every and index % update_every == 0:\n",
    "#         print(textwrap.dedent(f'''\n",
    "#             Progress: {index}/{authors_count} authors\n",
    "#             Total time: {time.time() - tic} s    \n",
    "#         ''').lstrip())\n",
    "        \n",
    "#         with open('benchmark.tmp', 'wb+') as tmp_file:\n",
    "#             pickle.dump({\n",
    "#                 'real_authors': real_authors,\n",
    "#                 'last_author_idx': index - 2,\n",
    "#             }, tmp_file)        \n",
    "            \n",
    "#         tic = time.time()\n",
    "\n",
    "print(f'Total time: {time.time() - total_tic} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esc_identifier.cluster import get_clusters, group_by_index\n",
    "from esc_identifier.author.distance import human_name_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar authors groups: 228\n",
      " "
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "\n",
    "same_authors_threshold = 0.98\n",
    "limit = 1500\n",
    "name_distance_threshold = 0.33\n",
    "\n",
    "query = (\n",
    "    session.query(author_table)\n",
    "    .order_by(author_table.c.name)\n",
    ")\n",
    "# todo: normalize authors\n",
    "authors = query[:limit]\n",
    "\n",
    "clusters_indices = get_clusters(\n",
    "    authors,\n",
    "    human_name_distance,\n",
    "    key=lambda author: author.name,\n",
    "    eps=name_distance_threshold\n",
    ")\n",
    "authors_groups = group_by_index(authors, clusters_indices)\n",
    "print(f'Similar authors groups: {len(authors_groups)}')\n",
    "\n",
    "for similar_authors in authors_groups:\n",
    "    real_authors = []\n",
    "#     for index, author_row in log_progress(similar_authors, every=10):\n",
    "    for index, author_row in enumerate(similar_authors):\n",
    "        author = Author(\n",
    "            kdd_id=author_row.id,\n",
    "            name=author_row.name,\n",
    "            affiliation=author_row.affiliation\n",
    "        )\n",
    "        normalized_author = normalize_author(author)\n",
    "\n",
    "        distances_with_real_authors = np.array([\n",
    "            author_distance(normalized_author, real_author)\n",
    "            for real_author\n",
    "            in real_authors\n",
    "        ])\n",
    "\n",
    "        if not len(distances_with_real_authors):\n",
    "            real_authors.append(to_real_author(author))\n",
    "            continue\n",
    "\n",
    "#         real_author_indices = np.arange(len(real_authors))[\n",
    "#             np.where(distances_with_real_authors[:, 0] < name_distance_threshold)\n",
    "#         ]\n",
    "\n",
    "#         if not len(real_author_indices):\n",
    "#             real_authors.append(to_real_author(author))\n",
    "#             continue\n",
    "\n",
    "        are_same_authors_probabilities = classifier.predict_proba(\n",
    "            distances_with_real_authors\n",
    "        )[:, 1]\n",
    "\n",
    "        if max(are_same_authors_probabilities) < same_authors_threshold:\n",
    "            real_authors.append(to_real_author(author))\n",
    "        else: \n",
    "            real_author_idx = int(np.argmax(are_same_authors_probabilities))\n",
    "            real_authors[real_author_idx].kdd_author_ids.append(author.kdd_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
